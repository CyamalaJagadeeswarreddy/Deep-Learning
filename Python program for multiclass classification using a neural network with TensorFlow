import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import load_iris
from tensorflow.keras import utils
# Load the Iris dataset
iris = load_iris()
X_data = iris.data
y_data = iris.target
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)
# Standardize the input features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Convert labels to one-hot encoding
y_train_one_hot = utils.to_categorical(y_train, num_classes=3)
y_test_one_hot = utils.to_categorical(y_test, num_classes=3)
# Define the multiclass classification model
model = tf.keras.Sequential([
tf.keras.layers.Dense(units=10, input_shape=(4,), activation='relu'),
tf.keras.layers.Dense(units=3, activation='softmax') # Output layer with softmax activation for
multiclass classification
])
# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# Train the model
model.fit(X_train, y_train_one_hot, epochs=50, validation_data=(X_test, y_test_one_hot))
# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test_one_hot)
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy:.4f}')
